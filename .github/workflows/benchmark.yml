name: Performance Benchmarks

# This workflow is manually triggered for performance benchmarking
# It runs comprehensive benchmarks that are not suitable for regular CI

on:
  workflow_dispatch:
    inputs:
      benchmark_type:
        description: 'Type of benchmark to run'
        required: true
        default: 'all'
        type: choice
        options:
          - 'all'
          - 'write'
          - 'read'
          - 'mixed'
      compare_baseline:
        description: 'Compare with baseline (main branch)'
        required: false
        default: true
        type: boolean

env:
  CARGO_TERM_COLOR: always

jobs:
  benchmark:
    name: Run Benchmarks
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest]
        rust: [stable]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          fetch-depth: 0  # Need full history for baseline comparison

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: ${{ matrix.rust }}

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-bench-${{ hashFiles('**/Cargo.lock') }}

      - name: Display benchmark configuration
        run: |
          echo "=== Benchmark Configuration ==="
          echo "Benchmark Type: ${{ inputs.benchmark_type }}"
          echo "Compare Baseline: ${{ inputs.compare_baseline }}"
          echo "OS: ${{ matrix.os }}"
          echo "Rust: ${{ matrix.rust }}"
          echo "==============================="

      - name: Run write benchmarks
        if: inputs.benchmark_type == 'write' || inputs.benchmark_type == 'all'
        run: |
          echo "Running write benchmarks..."
          cargo bench --bench write_bench -- --save-baseline current

      - name: Run read benchmarks
        if: inputs.benchmark_type == 'read' || inputs.benchmark_type == 'all'
        run: |
          echo "Running read benchmarks..."
          cargo bench --bench read_bench -- --save-baseline current

      - name: Run all benchmarks
        if: inputs.benchmark_type == 'all'
        run: |
          echo "Running all benchmarks..."
          cargo bench --all-features -- --save-baseline current

      - name: Checkout main branch for baseline
        if: inputs.compare_baseline == true
        run: |
          git stash || true
          git checkout main || git checkout master || echo "Could not checkout main branch"

      - name: Run baseline benchmarks
        if: inputs.compare_baseline == true
        continue-on-error: true
        run: |
          echo "Running baseline benchmarks..."
          cargo bench --all-features -- --save-baseline main || echo "Baseline benchmarks failed"

      - name: Return to original branch
        if: inputs.compare_baseline == true
        run: |
          git checkout -
          git stash pop || true

      - name: Generate benchmark report
        run: |
          echo "=== Benchmark Report ===" > benchmark-report.txt
          echo "Completed at: $(date)" >> benchmark-report.txt
          echo "Benchmark Type: ${{ inputs.benchmark_type }}" >> benchmark-report.txt
          echo "" >> benchmark-report.txt
          
          if [ -d "target/criterion" ]; then
            echo "Benchmark results saved in target/criterion/" >> benchmark-report.txt
            
            # List all benchmark results
            echo "" >> benchmark-report.txt
            echo "Available benchmarks:" >> benchmark-report.txt
            find target/criterion -name "index.html" | sed 's|target/criterion/||' >> benchmark-report.txt
          else
            echo "No benchmark results found" >> benchmark-report.txt
          fi
          
          cat benchmark-report.txt

      - name: Upload benchmark results
        uses: actions/upload-artifact@v5
        with:
          name: benchmark-results-${{ matrix.os }}-${{ github.run_number }}
          path: target/criterion/
          retention-days: 90

      - name: Upload benchmark report
        uses: actions/upload-artifact@v5
        with:
          name: benchmark-report-${{ matrix.os }}-${{ github.run_number }}
          path: benchmark-report.txt
          retention-days: 90

      - name: Display performance summary
        run: |
          echo "=== Performance Summary ==="
          echo ""
          echo "Benchmark artifacts have been uploaded."
          echo "Download the artifacts to view detailed HTML reports."
          echo ""
          echo "Key files to review:"
          echo "  - target/criterion/*/report/index.html (detailed reports)"
          echo "  - benchmark-report.txt (summary)"

  summary:
    name: Benchmark Summary
    runs-on: ubuntu-latest
    needs: benchmark
    if: always()
    steps:
      - name: Report completion
        run: |
          echo "=== Benchmark Completed ==="
          echo "Status: ${{ needs.benchmark.result }}"
          echo ""
          echo "To view results:"
          echo "1. Download the benchmark artifacts from this workflow run"
          echo "2. Open target/criterion/report/index.html in a browser"
          echo "3. Review benchmark-report.txt for a quick summary"
